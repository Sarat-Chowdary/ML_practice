{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27916d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: sarat chowdary\n",
    "# Roll No: S20200010107\n",
    "# Assignment: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d6415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code done below is an etension of the code done in the previous assignment.\n",
    "\n",
    "import random\n",
    "# Details of the implementaion of this code is in the attached ReadMe file\n",
    "\n",
    "# importing random to randomize test train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19487c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the dataset \n",
    "# Reading a csv file without any library imports\n",
    "# next(f) to skip headings\n",
    "\n",
    "iris_values = []\n",
    "\n",
    "f = open('iris.csv') \n",
    "next(f)\n",
    "data = [line.split(',') for line in f.readlines()]\n",
    "for row in data:\n",
    "    iris_values.append([float(row[0]), float(row[1]), float(row[2]), float(row[3]), int(row[4])])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695a8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the train and test arrays \n",
    "# splitting the dataset into train and test while keeping their corresponding target labels\n",
    "# using the random library to add randomness to the data initializing\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "random.shuffle(iris_values)\n",
    "len_train_set = 0\n",
    "\n",
    "for i in range(len(iris_values)):\n",
    "    len_train_set += 1\n",
    "    \n",
    "    if len_train_set < 121:\n",
    "        train.append([iris_values[i][0], iris_values[i][1], iris_values[i][2],\n",
    "                      iris_values[i][3], iris_values[i][4]])\n",
    "    else:\n",
    "        test.append([iris_values[i][0], iris_values[i][1], iris_values[i][2],\n",
    "                     iris_values[i][3], iris_values[i][4]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1557fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brain of the algorithm\n",
    "# Euclidian distances - sqrt(sum(square(difference between values of features of 2 samples)))\n",
    "\n",
    "def euclidian_distance(x1, x2):\n",
    "    total_result = 0\n",
    "    for i in range(4):\n",
    "        total_result += (x1[i] - x2[i])**2 \n",
    "    euclid_dis = total_result**(1/2)\n",
    "    return euclid_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef826891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Main code of the algorithm\n",
    "# This function takes a single sample and finds of which class it belongs to corresponding to the given dataset\n",
    "\n",
    "def sample_classifier(train_features_x, train_targets_y, sample, k=1):\n",
    "    distances = [euclidian_distance(sample, x) for x in train_features_x]\n",
    "    copy = distances\n",
    "    indices = []\n",
    "    mins = []\n",
    "    for i in range(k):\n",
    "        min = 10000000\n",
    "        for j in range(len(copy)):\n",
    "            if min>copy[j]:\n",
    "                min = copy[j]\n",
    "                key = j\n",
    "        indices.append(key)\n",
    "        copy[key] = 10000000\n",
    "        \n",
    "    y_values = [train_targets_y[indice] for indice in indices]\n",
    "    \n",
    "    class_1 = 0\n",
    "    class_2 = 0\n",
    "    class_3 = 0\n",
    "    \n",
    "    for i in range(len(y_values)):\n",
    "        if y_values[i] == 0:\n",
    "            class_1 += 1\n",
    "        if y_values[i] == 1:\n",
    "            class_2 += 1\n",
    "        if y_values[i] == 2:\n",
    "            class_3 += 1\n",
    "    \n",
    "    if class_1>class_2 and class_1 > class_3:\n",
    "        return 0\n",
    "    if class_2>class_1 and class_2 > class_3:\n",
    "        return 1\n",
    "    if class_3>class_2 and class_3 > class_2:\n",
    "        return 2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32730db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the 1nnc and 3nnc functions correspong to the k nearest neighbours algorithm\n",
    "\n",
    "def nearest_neighbour_c1(train_features_x, train_targets_y,test_features_x):\n",
    "    classes = []\n",
    "    for i in range(len(test_features_x)):\n",
    "        classes.append(sample_classifier(train_features_x, train_targets_y,test_features_x[i], 1))\n",
    "    return classes\n",
    "\n",
    "def nearest_neighbour_c3(train_features_x, train_targets_y,test_features_x):\n",
    "    classes = []\n",
    "    for i in range(len(test_features_x)):\n",
    "        classes.append(sample_classifier(train_features_x, train_targets_y,test_features_x[i], 3))\n",
    "    return classes\n",
    "\n",
    "def nearest_neighbour_cn(train_features_x, train_targets_y,test_features_x,n):\n",
    "    classes = []\n",
    "    for i in range(len(test_features_x)):\n",
    "        classes.append(sample_classifier(train_features_x, train_targets_y,test_features_x[i], n))\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819f5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy function to check how well the algorithms are working\n",
    "\n",
    "def accuracy_for_nearest_neighbour_c(train_features_x, train_targets_y,x,y,k=1):\n",
    "    sum_iterator = 0\n",
    "    if k == 1:\n",
    "        z = nearest_neighbour_c1(train_features_x, train_targets_y,x)\n",
    "    elif k==3:\n",
    "        z = nearest_neighbour_c3(train_features_x, train_targets_y,x)\n",
    "    else:\n",
    "        z = nearest_neighbour_cn(train_features_x, train_targets_y,x,k)\n",
    "    for i in range(len(z)):\n",
    "        if z[i] == y[i]:\n",
    "            sum_iterator+=1\n",
    "    \n",
    "    return sum_iterator/len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078c3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in the train set and returns mean and standard deviation for that k fold and n-nnc\n",
    "# divides the train set into train and validation set k times\n",
    "def k_fold_accuracy(k,n, iris_values):\n",
    "    len_train_set = 0\n",
    "    accuracy = 0\n",
    "    acc = []\n",
    "    mul=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(k):\n",
    "        \n",
    "        train_features_x = []\n",
    "        train_targets_y = []\n",
    "        test_features_x = []\n",
    "        test_targets_y = []\n",
    "        for i in range(int(mul), int(mul+len(iris_values)/k)):\n",
    "            test_features_x.append([iris_values[i][0], iris_values[i][1], iris_values[i][2], iris_values[i][3]])\n",
    "            test_targets_y.append(iris_values[i][4]) \n",
    "        for i in range(0, int(mul)):\n",
    "            train_features_x.append([iris_values[i][0], iris_values[i][1], iris_values[i][2], iris_values[i][3]])\n",
    "            train_targets_y.append(iris_values[i][4])\n",
    "        for i in range(int(mul+len(iris_values)/k), int(len(iris_values))):\n",
    "            train_features_x.append([iris_values[i][0], iris_values[i][1], iris_values[i][2], iris_values[i][3]])\n",
    "            train_targets_y.append(iris_values[i][4])\n",
    "        \n",
    "        mul+=(len(iris_values)/k)\n",
    "        temp = accuracy_for_nearest_neighbour_c(train_features_x,train_targets_y,test_features_x, test_targets_y,n)\n",
    "        acc.append(temp)\n",
    "        accuracy+=temp\n",
    "        \n",
    "#         print(accuracy)\n",
    "    mean = accuracy/k\n",
    "    std=0\n",
    "    for a in acc:\n",
    "        std += (a-mean)**2 \n",
    "    std/=k\n",
    "    std=std**(1/2)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b75326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final output for 1nnc\n",
    "# last assignment output\n",
    "# accuracy_for_nearest_neighbour_c(train_features_x, train_targets_y,test_features_x, test_targets_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "481ebced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final output for 3nnc\n",
    "# last assignment output\n",
    "# accuracy_for_nearest_neighbour_c(train_features_x, train_targets_y,test_features_x, test_targets_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6443082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding index/k-value with max accuracy\n",
    "# passing in only the train set\n",
    "acc = []\n",
    "for i in range(len(iris_values)):\n",
    "    a, std = k_fold_accuracy(5,i, train)\n",
    "    acc.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72395be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "index = acc.index(max(acc))\n",
    "print(acc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d4c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset into train and test set for checking test accuracy\n",
    "\n",
    "train_features_x = []\n",
    "train_targets_y = []\n",
    "test_features_x = []\n",
    "test_targets_y = []\n",
    "len_train_set=0\n",
    "\n",
    "for i in range(len(iris_values)):\n",
    "    len_train_set += 1\n",
    "    \n",
    "    if len_train_set < 121:\n",
    "        train_features_x.append([iris_values[i][0], iris_values[i][1], iris_values[i][2], iris_values[i][3]])\n",
    "        train_targets_y.append(iris_values[i][4])\n",
    "    else:\n",
    "        test_features_x.append([iris_values[i][0], iris_values[i][1], iris_values[i][2], iris_values[i][3]])\n",
    "        test_targets_y.append(iris_values[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e645ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy according to 5-fold-cross validation is for a 3 NNC with accuracy 0.9666666666666666\n",
      "The standard Deviation for k-fold-cross-validation of best knn is:  0.04082482904638632\n",
      "The test Accuracy for the best knn is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# outputs\n",
    "acc, std = k_fold_accuracy(5,index, train)\n",
    "print(\"The best accuracy according to 5-fold-cross validation is for a\",index,\"NNC with accuracy\",acc)\n",
    "\n",
    "print(\"The standard Deviation for k-fold-cross-validation of best knn is: \",std)\n",
    "\n",
    "print(\"The test Accuracy for the best knn is: \",accuracy_for_nearest_neighbour_c(train_features_x, train_targets_y,test_features_x, test_targets_y, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: sarat chowdary\n",
    "# Roll No: S20200010107\n",
    "# Assignment: 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
